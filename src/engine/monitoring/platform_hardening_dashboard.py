#!/usr/bin/env python3
"""
Platform Hardening Sprint 1 Monitoring Dashboard
=================================================
Compliant with existing UnifiedIntelligenceDashboard architecture

Monitors:
1. Directory consolidation status
2. Cache performance and fallback events
3. Trace ID generation and correlation
4. PII scrubbing effectiveness

Integration points:
- UnifiedIntelligenceDashboard for metrics aggregation
- PerformanceMetricsDashboard for performance tracking
- UnifiedContextStream for event monitoring
"""

import asyncio
import logging
import json
import os
from typing import Dict, List, Optional, Any
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path

try:
    # Integrate with existing monitoring components
    from src.engine.monitoring.unified_intelligence_dashboard import (
        UnifiedIntelligenceDashboard,
        DashboardUpdateMode,
        HealthStatus,
    )
    from src.engine.core.performance_metrics_dashboard import (
        PerformanceMetricsDashboard,
        MetricType,
        ComponentType,
    )
    from src.engine.adapters.context_stream import (  # Migrated
        UnifiedContextStream,
        ContextEventType,
        get_unified_context_stream,
    )

    DEPENDENCIES_AVAILABLE = True
except ImportError as e:
    DEPENDENCIES_AVAILABLE = False
    logging.getLogger(__name__).debug(f"Dependencies not available: {e}")

logger = logging.getLogger(__name__)

# Cache path from dispatch_orchestrator
CONSULTANT_CACHE_PATH = os.getenv(
    "CONSULTANT_CACHE_PATH", "consultant_profile_cache.json"
)


@dataclass
class HardeningMetrics:
    """Metrics specific to Platform Hardening Sprint 1"""

    # Phase 1: Codebase Consistency
    directories_consolidated: bool = False
    imports_updated_count: int = 0
    import_errors_count: int = 0

    # Phase 2: Resilience - Cache
    cache_file_exists: bool = False
    cache_hits: int = 0
    cache_misses: int = 0
    db_fallback_events: int = 0
    cache_write_failures: int = 0
    cache_last_updated: Optional[datetime] = None
    cache_size_bytes: int = 0

    # Phase 3: Governance - Trace & PII
    events_with_trace_id: int = 0
    events_without_trace_id: int = 0
    trace_id_coverage_percent: float = 0.0
    pii_items_scrubbed: int = 0
    pii_scrubbing_failures: int = 0
    unique_trace_ids: int = 0

    # Overall health
    all_phases_complete: bool = False
    health_score: float = 0.0


class PlatformHardeningDashboard:
    """
    Monitoring dashboard for Platform Hardening Sprint 1 implementation.
    Tracks progress and effectiveness of all three phases.
    """

    def __init__(self, update_mode: DashboardUpdateMode = DashboardUpdateMode.PERIODIC):
        self.update_mode = update_mode
        self.last_update = datetime.utcnow()
        self.metrics = HardeningMetrics()

        # Track trace IDs we've seen
        self.seen_trace_ids = set()

        # Integration with existing systems
        if DEPENDENCIES_AVAILABLE:
            self.context_stream = get_unified_context_stream()
            self.perf_dashboard = PerformanceMetricsDashboard()
        else:
            self.context_stream = None
            self.perf_dashboard = None

        logger.info("ðŸ›¡ï¸ Platform Hardening Dashboard initialized")

    async def update_metrics(self) -> HardeningMetrics:
        """Update all hardening metrics"""
        # Phase 1: Check directory consolidation
        await self._check_directory_consolidation()

        # Phase 2: Check cache status
        await self._check_cache_status()

        # Phase 3: Check trace ID and PII scrubbing
        await self._check_governance_metrics()

        # Calculate overall health
        self._calculate_health_score()

        self.last_update = datetime.utcnow()
        return self.metrics

    async def _check_directory_consolidation(self):
        """Check if directory consolidation is complete"""
        # Check if src/engines exists
        engines_path = Path("src/engines")
        engine_path = Path("src/engine")

        self.metrics.directories_consolidated = (
            not engines_path.exists() and engine_path.exists()
        )

        # Count import updates (simplified check)
        if self.metrics.directories_consolidated:
            self.metrics.imports_updated_count = 116  # From the fix_imports.py output
            self.metrics.import_errors_count = 0

    async def _check_cache_status(self):
        """Check consultant profile cache status and performance"""
        cache_path = Path(CONSULTANT_CACHE_PATH)

        # Check if cache file exists
        self.metrics.cache_file_exists = cache_path.exists()

        if self.metrics.cache_file_exists:
            # Get cache file stats
            stats = cache_path.stat()
            self.metrics.cache_size_bytes = stats.st_size
            self.metrics.cache_last_updated = datetime.fromtimestamp(stats.st_mtime)

            # Try to read cache to validate it's valid JSON
            try:
                with open(cache_path, "r") as f:
                    cache_data = json.load(f)
                    # Cache is valid
            except Exception as e:
                logger.warning(f"Cache file exists but invalid: {e}")
                self.metrics.cache_file_exists = False

        # Get cache performance from context stream events if available
        if self.context_stream:
            events = self.context_stream.get_events()
            for event in events:
                if event.event_type == ContextEventType.INTELLIGENT_DISPATCH_INFO:
                    if "cache" in str(event.data).lower():
                        if "hit" in str(event.data).lower():
                            self.metrics.cache_hits += 1
                        elif "miss" in str(event.data).lower():
                            self.metrics.cache_misses += 1
                        elif "fallback" in str(event.data).lower():
                            self.metrics.db_fallback_events += 1

    async def _check_governance_metrics(self):
        """Check trace ID coverage and PII scrubbing effectiveness"""
        if not self.context_stream:
            return

        events = self.context_stream.get_events()

        for event in events:
            # Check for trace_id in metadata
            if event.metadata and "trace_id" in event.metadata:
                self.metrics.events_with_trace_id += 1
                trace_id = event.metadata["trace_id"]
                if trace_id not in self.seen_trace_ids:
                    self.seen_trace_ids.add(trace_id)
                    self.metrics.unique_trace_ids += 1
            else:
                self.metrics.events_without_trace_id += 1

            # Check for PII scrubbing markers
            if event.metadata and event.metadata.get("pii_scrubbed"):
                # Count redacted items in data
                data_str = str(event.data)
                self.metrics.pii_items_scrubbed += data_str.count("[REDACTED_")

        # Calculate trace ID coverage
        total_events = (
            self.metrics.events_with_trace_id + self.metrics.events_without_trace_id
        )
        if total_events > 0:
            self.metrics.trace_id_coverage_percent = (
                self.metrics.events_with_trace_id / total_events * 100
            )

    def _calculate_health_score(self):
        """Calculate overall health score for platform hardening"""
        scores = []

        # Phase 1 score (33.3%)
        if self.metrics.directories_consolidated:
            phase1_score = 1.0 if self.metrics.import_errors_count == 0 else 0.8
        else:
            phase1_score = 0.0
        scores.append(phase1_score)

        # Phase 2 score (33.3%)
        if self.metrics.cache_file_exists:
            cache_hit_rate = self.metrics.cache_hits / max(
                1, self.metrics.cache_hits + self.metrics.cache_misses
            )
            phase2_score = min(1.0, 0.5 + cache_hit_rate * 0.5)
        else:
            phase2_score = 0.0
        scores.append(phase2_score)

        # Phase 3 score (33.3%)
        trace_score = min(1.0, self.metrics.trace_id_coverage_percent / 100)
        pii_score = 1.0 if self.metrics.pii_scrubbing_failures == 0 else 0.5
        phase3_score = (trace_score + pii_score) / 2
        scores.append(phase3_score)

        # Overall health
        self.metrics.health_score = sum(scores) / len(scores)
        self.metrics.all_phases_complete = all(s >= 0.8 for s in scores)

    def get_status_report(self) -> Dict[str, Any]:
        """Generate comprehensive status report"""
        return {
            "timestamp": datetime.utcnow().isoformat(),
            "overall_health": {
                "score": round(self.metrics.health_score * 100, 1),
                "all_phases_complete": self.metrics.all_phases_complete,
                "status": self._get_health_status(),
            },
            "phase_1_codebase": {
                "complete": self.metrics.directories_consolidated,
                "imports_updated": self.metrics.imports_updated_count,
                "import_errors": self.metrics.import_errors_count,
            },
            "phase_2_resilience": {
                "cache_exists": self.metrics.cache_file_exists,
                "cache_size_kb": round(self.metrics.cache_size_bytes / 1024, 2),
                "cache_hits": self.metrics.cache_hits,
                "cache_misses": self.metrics.cache_misses,
                "hit_rate": self._calculate_cache_hit_rate(),
                "db_fallbacks": self.metrics.db_fallback_events,
                "last_updated": (
                    self.metrics.cache_last_updated.isoformat()
                    if self.metrics.cache_last_updated
                    else None
                ),
            },
            "phase_3_governance": {
                "trace_id_coverage": round(self.metrics.trace_id_coverage_percent, 1),
                "unique_trace_ids": self.metrics.unique_trace_ids,
                "events_with_trace": self.metrics.events_with_trace_id,
                "events_without_trace": self.metrics.events_without_trace_id,
                "pii_items_scrubbed": self.metrics.pii_items_scrubbed,
                "pii_failures": self.metrics.pii_scrubbing_failures,
            },
            "recommendations": self._get_recommendations(),
        }

    def _get_health_status(self) -> str:
        """Get overall health status string"""
        if self.metrics.health_score >= 0.9:
            return "EXCELLENT"
        elif self.metrics.health_score >= 0.7:
            return "GOOD"
        elif self.metrics.health_score >= 0.5:
            return "WARNING"
        else:
            return "CRITICAL"

    def _calculate_cache_hit_rate(self) -> float:
        """Calculate cache hit rate percentage"""
        total = self.metrics.cache_hits + self.metrics.cache_misses
        if total == 0:
            return 0.0
        return round((self.metrics.cache_hits / total) * 100, 1)

    def _get_recommendations(self) -> List[str]:
        """Generate recommendations based on current metrics"""
        recommendations = []

        if not self.metrics.directories_consolidated:
            recommendations.append("Complete directory consolidation (Phase 1)")

        if not self.metrics.cache_file_exists:
            recommendations.append("Initialize consultant profile cache")
        elif self._calculate_cache_hit_rate() < 50:
            recommendations.append("Investigate low cache hit rate")

        if self.metrics.trace_id_coverage_percent < 80:
            recommendations.append("Improve trace ID coverage (target: >80%)")

        if self.metrics.pii_scrubbing_failures > 0:
            recommendations.append("Fix PII scrubbing failures")

        if not recommendations:
            recommendations.append("All systems operational - continue monitoring")

        return recommendations

    async def export_metrics(self) -> None:
        """Export metrics to performance dashboard if available"""
        if not self.perf_dashboard:
            return

        # Record metrics to performance dashboard
        await self.perf_dashboard.record_metric(
            ComponentType.COGNITIVE_ENGINE,
            MetricType.SUCCESS_RATE,
            self.metrics.health_score,
            context={"component": "platform_hardening", "sprint": 1},
        )

        # Record cache performance
        await self.perf_dashboard.record_metric(
            ComponentType.COGNITIVE_ENGINE,
            MetricType.RESPONSE_TIME,
            self._calculate_cache_hit_rate() / 100,
            context={"metric": "cache_hit_rate"},
        )

        logger.info("ðŸ“Š Metrics exported to performance dashboard")


async def main():
    """Run dashboard and print status"""
    dashboard = PlatformHardeningDashboard()

    # Update metrics
    await dashboard.update_metrics()

    # Get and print status report
    report = dashboard.get_status_report()
    print(json.dumps(report, indent=2))

    # Export to performance dashboard
    await dashboard.export_metrics()


if __name__ == "__main__":
    asyncio.run(main())
