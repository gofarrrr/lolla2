"""
WeightedArbitrationService
==========================

Algorithmic service for weighted arbitration operations.
Delegates to host manager's fallback implementations for all operations.

RESURRECTED VIA OPERATION PHOENIX - Guided Reconstruction Protocol
"""

from __future__ import annotations

import logging
from typing import List, Dict, Any, TYPE_CHECKING

if TYPE_CHECKING:
    from src.arbitration.models import ConsultantRole, UserWeightingPreferences

logger = logging.getLogger(__name__)


class WeightedArbitrationService:
    """
    Algorithmic service for weighted arbitration

    This service delegates all operations to the host manager's
    proven fallback implementations, ensuring consistency and
    reliability in weighted decision-making.
    """

    def __init__(self):
        """Initialize weighted arbitration service"""
        logger.info("üîß WeightedArbitrationService initialized")

    async def generate_weighted_recommendations(
        self,
        host: Any,
        consultant_outputs: List[Any],
        user_preferences: Any,
    ) -> List[str]:
        """
        Generate weighted recommendations

        Args:
            host: Host manager with fallback implementation
            consultant_outputs: All consultant outputs
            user_preferences: User's weighting preferences

        Returns:
            List[str]: Weighted recommendations
        """
        logger.info("üîÑ Delegating weighted recommendations to host manager")
        return await host.generate_weighted_recommendations(
            consultant_outputs, user_preferences
        )

    async def generate_weighted_insights(
        self,
        host: Any,
        consultant_outputs: List[Any],
        user_preferences: Any,
    ) -> List[str]:
        """
        Generate weighted insights

        Args:
            host: Host manager with fallback implementation
            consultant_outputs: All consultant outputs
            user_preferences: User's weighting preferences

        Returns:
            List[str]: Weighted insights
        """
        logger.info("üîç Delegating weighted insights to host manager")
        return await host.generate_weighted_insights(
            consultant_outputs, user_preferences
        )

    async def generate_weighted_risk_assessment(
        self,
        host: Any,
        consultant_outputs: List[Any],
        user_preferences: Any,
    ) -> str:
        """
        Generate weighted risk assessment

        Args:
            host: Host manager with fallback implementation
            consultant_outputs: All consultant outputs
            user_preferences: User's weighting preferences

        Returns:
            str: Comprehensive risk assessment
        """
        logger.info("‚ö†Ô∏è Delegating weighted risk assessment to host manager")
        return await host.generate_weighted_risk_assessment(
            consultant_outputs, user_preferences
        )

    async def generate_alternative_scenarios(
        self,
        host: Any,
        consultant_outputs: List[Any],
        user_preferences: Any,
        merit_assessments: Dict[Any, Any],
    ) -> List[Dict[str, Any]]:
        """
        Generate alternative scenarios

        Args:
            host: Host manager with fallback implementation
            consultant_outputs: All consultant outputs
            user_preferences: User's weighting preferences
            merit_assessments: Merit assessments for each consultant

        Returns:
            List[Dict]: Alternative decision scenarios
        """
        logger.info("üé≠ Generating alternative scenarios (minimal implementation)")

        # Generate simple alternative scenarios based on different consultant weights
        scenarios = []

        # Scenario 1: Prioritize highest merit consultant
        if merit_assessments:
            highest_merit_role = max(
                merit_assessments.keys(),
                key=lambda role: getattr(merit_assessments[role], 'overall_merit_score', 0.0)
            )
            scenarios.append({
                "name": "Merit-Optimized Approach",
                "description": f"Prioritize {highest_merit_role.value} consultant based on highest overall merit",
                "primary_consultant": highest_merit_role,
                "expected_outcome": "Maximum analytical depth and quality",
                "risk_profile": "Low risk, high confidence",
            })

        # Scenario 2: Balanced approach
        scenarios.append({
            "name": "Balanced Multi-Consultant Synthesis",
            "description": "Equal weight to top consultants for comprehensive perspective",
            "primary_consultant": None,
            "expected_outcome": "Comprehensive analysis with multiple viewpoints",
            "risk_profile": "Moderate risk, balanced confidence",
        })

        # Scenario 3: User preference aligned
        if user_preferences and hasattr(user_preferences, 'consultant_weights'):
            highest_pref_role = max(
                user_preferences.consultant_weights.keys(),
                key=lambda role: user_preferences.consultant_weights[role]
            )
            scenarios.append({
                "name": "User-Preference Aligned",
                "description": f"Align with user's highest weighted preference: {highest_pref_role.value}",
                "primary_consultant": highest_pref_role,
                "expected_outcome": "Maximum alignment with user priorities",
                "risk_profile": "User-defined risk tolerance",
            })

        logger.info(f"‚úÖ Generated {len(scenarios)} alternative scenarios")
        return scenarios

    async def generate_implementation_guidance(
        self,
        host: Any,
        consultant_outputs: List[Any],
        user_preferences: Any,
        differential_analysis: Any,
    ) -> str:
        """
        Generate implementation guidance

        Args:
            host: Host manager with fallback implementation
            consultant_outputs: All consultant outputs
            user_preferences: User's weighting preferences
            differential_analysis: Complete differential analysis

        Returns:
            str: Implementation guidance and roadmap
        """
        logger.info("üõ†Ô∏è Generating implementation guidance")

        # Extract consultant count
        consultant_count = len(consultant_outputs) if consultant_outputs else 0

        # Generate structured implementation guidance
        guidance_parts = [
            "Implementation Roadmap:",
            f"\n1. Foundation Phase: Integrate insights from {consultant_count} consultant perspectives",
            "\n2. Prioritization: Focus on highest-weighted recommendations based on user preferences",
            "\n3. Risk Mitigation: Address identified risks through phased rollout and monitoring",
            "\n4. Validation: Establish success metrics and feedback loops",
            "\n5. Iteration: Adjust approach based on early results and stakeholder feedback",
        ]

        # Add user context if available
        if user_preferences and hasattr(user_preferences, 'context_preferences'):
            context = user_preferences.context_preferences
            if context:
                guidance_parts.append(
                    f"\n\nContext-Specific Considerations: "
                    f"Tailor implementation to {', '.join(str(v) for v in list(context.values())[:3])}"
                )

        guidance = " ".join(guidance_parts)
        logger.info("‚úÖ Generated implementation guidance")
        return guidance

    def determine_primary_consultant(
        self,
        differential_analysis_proxy: Any,
        user_preferences: Any,
    ) -> Any:
        """
        Determine primary consultant recommendation

        Args:
            differential_analysis_proxy: Proxy object with merit_assessments
            user_preferences: User's weighting preferences

        Returns:
            ConsultantRole: Primary consultant recommendation
        """
        logger.info("üéØ Determining primary consultant")

        merit_assessments = differential_analysis_proxy.merit_assessments

        # Calculate combined scores: merit + user preference
        combined_scores = {}

        for role, assessment in merit_assessments.items():
            merit_score = getattr(assessment, 'overall_merit_score', 0.0)
            query_fitness = getattr(assessment, 'query_fitness_score', 0.0)
            user_weight = user_preferences.consultant_weights.get(role, 0.0)

            # Weighted combination: 40% merit + 30% fitness + 30% user preference
            combined_score = (
                merit_score * 0.4 +
                query_fitness * 0.3 +
                user_weight * 0.3
            )
            combined_scores[role] = combined_score

        # Select consultant with highest combined score
        primary_consultant = max(combined_scores.keys(), key=lambda k: combined_scores[k])

        logger.info(f"üéØ Primary consultant: {primary_consultant.value} (score: {combined_scores[primary_consultant]:.2f})")
        return primary_consultant

    def generate_supporting_rationales(
        self,
        analysis_proxy: Any,
        user_preferences: Any,
    ) -> Dict[Any, str]:
        """
        Generate supporting rationales for each consultant

        Args:
            analysis_proxy: Proxy object with merit_assessments
            user_preferences: User's weighting preferences

        Returns:
            Dict[ConsultantRole, str]: Rationales for each consultant
        """
        logger.info("üìù Generating supporting rationales")

        merit_assessments = analysis_proxy.merit_assessments
        rationales = {}

        for role, assessment in merit_assessments.items():
            merit_score = getattr(assessment, 'overall_merit_score', 0.0)
            fitness_score = getattr(assessment, 'query_fitness_score', 0.0)
            strengths = getattr(assessment, 'strengths', [])
            confidence = getattr(assessment, 'confidence_level', merit_score)

            # Generate contextual rationale
            rationale_parts = [
                f"{role.name} brings",
                f"merit score of {merit_score:.2f}",
                f"and query fitness of {fitness_score:.2f}.",
            ]

            if strengths:
                rationale_parts.append(
                    f"Key strengths: {', '.join(strengths[:2])}."
                )

            rationale_parts.append(
                f"Confidence level: {confidence:.2f}."
            )

            rationales[role] = " ".join(rationale_parts)

        logger.info(f"‚úÖ Generated rationales for {len(rationales)} consultants")
        return rationales
